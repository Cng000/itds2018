{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Dive Week 6/7: Logistic Regression \n",
    "\n",
    "This week we take a look at *logistic regression*, the first classification model we'll be covering in class. We'll be using `scikit-learn` in today's exercise. \n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "As we discussed last week, logisitic regression is a *classification model* - meaning that it is designed to idenfity the likelihood that a given observed data point belongs to set class, or category. Today we'll be looking at a real world application of logistic regression using data from loans requests posted on [Kiva.org](kiva.org). \n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://www-kiva-org.global.ssl.fastly.net/cms/sites/default/files/kivablog/preview_logo_1.jpg)\n",
    "\n",
    "Kiva is an international nonprofit, founded in 2005 and based in San Francisco, with a mission to connect people through lending to alleviate poverty. Kiva seeks to celebrate and support people looking to create a better future for themselves, their families and their communities.\n",
    "\n",
    "*By lending as little as $25 on Kiva, anyone can help a borrower start or grow a business, go to school, access clean energy or realize their potential. For some, it’s a matter of survival, for others it’s the fuel for a life-long ambition.*\n",
    "\n",
    "## Today's Modeling Objective\n",
    "Our focus today will be determining whether microfinance projects on the site [Kiva.org](kiva.org) receive funding or not using a host of features made available by Kiva, along with some features we'll design ourselves. \n",
    "\n",
    "Today's data is a subsample of projects in Kenya, one of Kiva's most active countries for lending. We'll be working with 18,000 observation, 3,000 or which were funded. \n",
    "\n",
    "Documentation on the data is available on [Kiva's website](http://build.kiva.org/docs/data/basic_types)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://grantmlong.com/data/kiva_kenya_sample.csv')\n",
    "print(df.shape)\n",
    "print(list(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidying Up Our Data\n",
    "\n",
    "There are a couple of different things we'll want to off the bat: \n",
    " 1. Create a target variable\n",
    " 2. Generate a more usable version of the `POSTED_TIME` column.\n",
    " 3. Generate a variable with the amount of planned time before expiration for each project. \n",
    " \n",
    " \n",
    " #####  Based on a quick look at the data, what else might be interesting to try off the bat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.STATUS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['success'] = (df.STATUS=='funded')*1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.POSTED_TIME.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['posted_year'] = pd.to_datetime(df.POSTED_TIME).dt.year\n",
    "df['posted_duration'] = (pd.to_datetime(df.PLANNED_EXPIRATION_TIME)\n",
    "                             - pd.to_datetime(df.POSTED_TIME)\n",
    "                            ).dt.days\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "Which columns might be helpful in predicting successful funding? How do we know?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'ACTIVITY_NAME'\n",
    "(df[[var, 'success']]\n",
    " .groupby(var)\n",
    " .agg(['count', 'mean'])\n",
    " .sort_values(by=('success', 'count'), ascending=False)\n",
    " .head(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.success==1) & (df.LOAN_AMOUNT<=2000), 'LOAN_AMOUNT'].hist(bins=20, alpha=.6, color='blue')\n",
    "df.loc[(df.success==0) & (df.LOAN_AMOUNT<=2000), 'LOAN_AMOUNT'].hist(bins=20, alpha=.6, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.posted_year>2010,['posted_year', 'posted_duration']].groupby('posted_year').median().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.LENDER_TERM.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training A Model in `statsmodels`\n",
    "\n",
    "As we saw the past two weeks, `statsmodels` can be helpful if we want to visualize the summary statistics of our output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's identify the columns we're interested in and extract the rows with valid results. We'll also want to add a constant column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['constant'] = 1\n",
    "model_columns = ['constant', 'LOAN_AMOUNT', 'posted_year', 'posted_duration', 'LENDER_TERM']\n",
    "valids = df[model_columns].notna().all(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's use `statsmodels` to fit the model and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = sm.Logit(df.loc[valids, 'success'], df.loc[valids, model_columns])\n",
    "result = logit.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training A Model in `sklearn`\n",
    "\n",
    "As we saw the past two weeks, `statsmodels` can be helpful if we want to visualize the summary statistics of our output. Documentation for the `LogisticRegression` object can be found [here](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_columns = ['LOAN_AMOUNT', 'posted_year', 'posted_duration', 'LENDER_TERM']\n",
    "valids = df[model_columns].notna().all(axis=1)\n",
    "X = df.loc[valids, model_columns].values\n",
    "y = df.loc[valids, 'success'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's fit and score the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=20181022).fit(X, y)\n",
    "print('The accuracy of our model is %0.1f%%' % (clf.score(X, y)*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's see where we went right and where we went wrong:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[valids, 'likelihood'] = clf.predict_proba(X)[:,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the top values where we predicted incorrectly predicted a failure to fund: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(valids & (df.success==1)), ].sort_values(by='likelihood').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at where we predicted funding, but the projects were not funded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(valids & (df.success==0)), ].sort_values(by='likelihood').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's take a closer look at our summary metrics. How do they change as we change our cutoff value for our prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(df, threshold):\n",
    "    \n",
    "    df['predicted'] = (clf.predict_proba(X)[:,1]>=threshold)*1\n",
    "    accuracy = sum(df['predicted']==y)/len(y)\n",
    "    precision = df.loc[df.predicted==1, 'success'].mean()\n",
    "    recall = df.loc[df.success==1, 'predicted'].mean()\n",
    "    \n",
    "    return accuracy, precision, recall, sum(df['predicted'])\n",
    "\n",
    "for p in [.4, .5, .6, .9]:\n",
    "    print(p, calculate_metrics(df.loc[valids,].copy(), p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
